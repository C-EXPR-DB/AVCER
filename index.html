<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="description"
        content="Audio-Visual Compound Expression Recognition Method based on Late Modality Fusion and Rule-based Decision">
    <meta name="keywords" content="CVPRW 2024">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Audio-Visual Compound Expression Recognition Method based on Late Modality Fusion and Rule-based Decision</title>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">

    <link rel="icon" type="image/png" href="./static/favicon/favicon-16x16.png" sizes="16x16">
    <link rel="icon" type="image/png" href="./static/favicon/favicon-32x32.png" sizes="32x32">
    <link rel="shortcut icon" href="./static/favicon/favicon.ico" type="image/x-icon">

    <link rel="apple-touch-icon" href="./static/favicon/apple-touch-icon.png">
    <link href="https://fonts.googleapis.com/css?family=Merriweather:400,900,900i" rel="stylesheet">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/comp-slider.js" defer></script>
    <script src="./static/js/index.js"></script>
</head>
<body>
    <a id="btt-button">
        <svg xmlns="http://www.w3.org/2000/svg" width="30" height="30" viewBox="0 0 24 24">
            <polygon points="12 6.586 3.293 15.293 4.707 16.707 12 9.414 19.293 16.707 20.707 15.293 12 6.586"/>
        </svg>
    </a>

    <section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
        <div class="columns is-centered">
            <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
                Audio-Visual Compound Expression Recognition Method based on Late Modality Fusion and Rule-based Decision
            </h1>
            <div class="is-size-5 publication-authors">
                <span class="author-block">
                <a href="https://hci.nw.ru/en/employees/14" target="_blank">Elena Ryumina</a><a class="git-link" href="https://github.com/ElenaRyumina" target="_blank"><span class="icon"><i class="fab fa-github"></i></span></a><sup>1</sup>,</span>
                <span class="author-block">
                <a href="https://hci.nw.ru/en/employees/10" target="_blank">Maxim Markitantov</a><sup>1</sup>,</span>
                <span class="author-block">
                <a href="https://hci.nw.ru/en/employees/3" target="_blank">Dmitry Ryumin</a><a class="git-link" href="https://github.com/DmitryRyumin" target="_blank"><span class="icon"><i class="fab fa-github"></i>
                    </span></a><a class="git-link" href="https://dmitryryumin.github.io/" target="_blank"><span class="icon"><i class="fas fa-globe"></i>
                    </span></a><sup>1</sup>,</span>
                <span class="author-block">Heysem Kaya<sup>2</sup>,
                </span>
                <span class="author-block">
                <a href="https://hci.nw.ru/en/employees/1" target="_blank">Alexey Karpov</a><sup>1</sup>,
                </span>
            </div>

            <div class="is-size-5 publication-authors">
                <span class="author-block"><sup>1</sup> St. Petersburg Institute for Informatics and Automation of the Russian Academy of Sciences, <a href="https://spcras.ru/en/" target="_blank">St. Petersburg Federal Research Center of the Russian Academy of Sciences (SPC RAS)</a>, St. Petersburg, Russia</span>
                <span class="author-block"><sup>2</sup> Department of Information and Computing Sciences Utrecht University, The Netherlands</span>
                <br />
                <!-- <span><a href="https://affective-behavior-analysis-in-the-wild.github.io/6th/" target="_blank">CVPRW 2024</a> (submitted)</span> -->
            </div>

            <div class="column has-text-centered">
                <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                    <a href="https://arxiv.org/abs/2403.12687"
                    target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                    </a>
                </span>
                <!-- <span class="link-block">
                    <a href="#"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                    </a>
                </span> -->
                <!-- Code Link. -->
                <span class="link-block">
                    <a href="https://github.com/C-EXPR-DB/AVCER/tree/main/src/" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                    </a>
                </span>
                <!-- Model Link. -->
                <span class="link-block">
                    <a href="#" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span>ðŸ¤— Model (coming soon)</span>
                    </a>
                </span>
                <!-- Demo Link. -->
                <span class="link-block">
                    <a href="#"
                    class="external-link button is-normal is-rounded is-dark">
                    <span>ðŸ¤— Demo (coming soon)</span>
                    </a>
                </span>
                </div>
            </div>
            </div>
        </div>
        </div>
    </div>
    </section>
    <section class="section" style="padding: 0; margin:0">

        <div class="TODO-section">
            <div class="container is-max-desktop">
                <div class="columns is-centered has-text-centered">
                    <div class="column is-four-fifths">
                        <h2 class="title is-5">TODO List</h2>
                        <div class="content has-text-justified">
                            <svg viewBox="0 0 0 0" style="position: absolute; z-index: -1; opacity: 0;">
                                <defs>
                                    <path id="todo__line" stroke="#363636" d="M21 12.3h280v0.1z" ></path>
                                    <path id="todo__box" stroke="#363636" d="M21 12.7v5c0 1.3-1 2.3-2.3 2.3H8.3C7 20 6 19 6 17.7V7.3C6 6 7 5 8.3 5h10.4C20 5 21 6 21 7.3v5.4"></path>
                                    <path id="todo__check" stroke="#2b8f30" d="M10 13l2 2 5-5"></path>
                                    <circle id="todo__circle" cx="13.5" cy="12.5" r="10"></circle>
                                </defs>
                            </svg>
                            <div class="todo-list">

                            <label class="todo">
                                <input class="todo__state" type="checkbox" />

                                <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 300 25" class="todo__icon">
                                <use xlink:href="#todo__line" class="todo__line"></use>
                                <use xlink:href="#todo__box" class="todo__box"></use>
                                <use xlink:href="#todo__check" class="todo__check"></use>
                                <use xlink:href="#todo__circle" class="todo__circle"></use>
                                </svg>

                                <div class="todo__text">GitHub page creation</div>
                            </label>

                            <label class="todo">
                                <input class="todo__state" type="checkbox" />

                                <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 300 25" class="todo__icon">
                                <use xlink:href="#todo__line" class="todo__line"></use>
                                <use xlink:href="#todo__box" class="todo__box"></use>
                                <use xlink:href="#todo__check" class="todo__check"></use>
                                <use xlink:href="#todo__circle" class="todo__circle"></use>
                                </svg>

                                <div class="todo__text">arXiv paper submission</div>
                            </label>

                            <label class="todo">
                                <input class="todo__state" type="checkbox" />

                                <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 300 25" class="todo__icon">
                                <use xlink:href="#todo__line" class="todo__line"></use>
                                <use xlink:href="#todo__box" class="todo__box"></use>
                                <use xlink:href="#todo__check" class="todo__check"></use>
                                <use xlink:href="#todo__circle" class="todo__circle"></use>
                                </svg>

                                <div class="todo__text">Release code</div>
                            </label>

                            <label class="todo">
                                <input class="todo__state" type="checkbox" />

                                <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 300 25" class="todo__icon">
                                <use xlink:href="#todo__line" class="todo__line"></use>
                                <use xlink:href="#todo__box" class="todo__box"></use>
                                <use xlink:href="#todo__check" class="todo__check"></use>
                                <use xlink:href="#todo__circle" class="todo__circle"></use>
                                </svg>

                                <div class="todo__text">Release Models and Demo (soon) </div>
                            </label>

                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="abstract-section">
            <div class="container is-max-desktop abstract-sect">
                <div class="columns is-centered has-text-centered">
                    <div class="column is-four-fifths">
                        <h2 class="title is-3">Abstract</h2>
                        <div class="content has-text-justified">
                            <p>
                                This paper presents the results of the SUN team for the CE Recognition Challenge of the 6th ABAW Competition. We propose a novel audio-visual method for compound expression recognition. Our method relies on emotion recognition models that fuse modalities at the emotion probability level, while decisions regarding the prediction of compound expressions are based on predefined rules. Notably, our method does not use any training data specific to the target task. Thus, the problem is thus, a zero-shot classification task. The method is evaluated in multi-corpus training and cross-corpus validation setups. Our findings from the challenge demonstrate that the proposed method can potentially form a basis for developing intelligent tools for annotating audio-visual data in the context of human's basic and compound emotions.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="pipeline-section">
            <div class="container is-max-desktop">
                <div class="pipeline">
                    <div class="columns is-centered has-text-centered">
                        <div class="column is-four-fifths">
                            <h2 class="title is-3">Pipeline of the proposed audio-visual CER method</h2>
                            <img class="img-method" src="./static/img/Pipeline.png" alt="pipeline">
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="pipeline-section">
            <div class="container is-max-desktop">
                <div class="pipeline">
                    <div class="columns is-centered has-text-centered">
                        <div class="column is-four-fifths">
                            <h2 class="title is-3">An example of CEs prediction using video from the C-EXPR-DB corpus</h2>
                            <img class="img-method" src="./static/img/Predictions.png" alt="pipeline">
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="conclusion-section">
            <div class="container is-max-desktop">
                <div class="conclusion">
                    <div class="columns is-centered has-text-centered">
                        <div class="column is-four-fifths">
                            <h2 class="title is-3">Conclusion</h2>
                            <div class="content has-text-justified">
                                <p>
                                In this paper, we propose a novel audio-visual method for CER. The method integrates three models, including the static and dynamic visual models, as well as the audio model. Each model predicts the emotion probabilities for six basic emotions and the neutral state. The emotional probabilities are then weighted utilizing the Dirichlet distribution. Finally, two rules are applied to determine CE. Additionally, We provide new baselines for recognizing seven emotions on the Validation subsets of the AffWild2 and AFEW corpora.
                                </p>
                                <p>
                                The experimental results demonstrate that each model is responsible for predicting specific CE. For example, the audio model is responsible for predicting the Angry Surprised and Sadly Angry, the static visual model is responsible for predicting the Happily Surprised class, and the dynamic visual model well predicts other CE. The results obtained show that the proposed method can potentially lead to intelligent software tools for fast annotation of data containing both basic and compound emotional expressions.
                                </p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <footer class="footer">
        <div class="container">
        <div class="content has-text-centered">
            <a class="icon-link external-link" href="https://github.com/C-EXPR-DB" target="_blank">
            <i class="fab fa-github"></i>
            </a>
        </div>
        <div class="columns is-centered">
            <div class="column is-8">
            <div class="content">
                <p>
                This page was built using the <a href="https://github.com/C-EXPR-DB/AVCER" target="_blank">AVCER project page</a>, which was adopted from theÂ <a href="https://nerfies.github.io" target="_blank">Nerfies</a>Â project page.
                You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
                </p>
            </div>
            </div>
        </div>
        </div>
    </footer>
</body>
</html>
